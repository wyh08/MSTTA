{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "242fbc08-ff37-43ba-a92b-293c0625f9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.2066, Test Accuracy: 0.4778, Test F1: 0.4378\n",
      "Simple Accuracy: 0.4778, Precision: 0.4907, Recall: 0.4778, F1: 0.4378\n",
      "T_TTA average - Accuracy: 0.4783, Precision: 0.5025, Recall: 0.4783, F1: 0.4327\n",
      "R_TTA average - Accuracy: 0.4751, Precision: 0.4941, Recall: 0.4751, F1: 0.4314\n",
      "MSTTA average - Accuracy: 0.4837, Precision: 0.5058, Recall: 0.4837, F1: 0.4389\n",
      "T_TTA uncertainty - Accuracy: 0.4796, Precision: 0.5022, Recall: 0.4796, F1: 0.4374\n",
      "R_TTA uncertainty - Accuracy: 0.4760, Precision: 0.4973, Recall: 0.4760, F1: 0.4342\n",
      "MSTTA uncertainty - Accuracy: 0.4833, Precision: 0.5038, Recall: 0.4833, F1: 0.4400\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import random\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class SST5Dataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer, max_len):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.data.iloc[idx]['sentence']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "\n",
    "       \n",
    "        encoding = self.tokenizer(\n",
    "            sentence,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class HuggingFaceEmbedding(nn.Module):\n",
    "    def __init__(self, model_name=\"bert-base-uncased\", freeze=True):\n",
    "        super(HuggingFaceEmbedding, self).__init__()\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.embedding_model = BertModel.from_pretrained(model_name)\n",
    "        if freeze:\n",
    "            for param in self.embedding_model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.embedding_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.last_hidden_state  \n",
    "\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, transformer_model_name, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.embedding = HuggingFaceEmbedding(model_name=transformer_model_name, freeze=True)\n",
    "        embedding_dim = self.embedding.embedding_model.config.hidden_size\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\n",
    "                            bidirectional=True, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embedded = self.embedding(input_ids, attention_mask)\n",
    "        lstm_out, _ = self.lstm(self.dropout(embedded))\n",
    "        \n",
    "        forward_last_hidden = lstm_out[:, -1, :self.lstm.hidden_size]\n",
    "        backward_last_hidden = lstm_out[:, 0, self.lstm.hidden_size:]\n",
    "        \n",
    "        last_hidden = torch.cat((forward_last_hidden, backward_last_hidden), dim=1)\n",
    "\n",
    "        return self.fc(self.dropout(last_hidden))\n",
    "\n",
    "def create_data_loader(file_path, tokenizer, max_len, batch_size, shuffle):\n",
    "    dataset = SST5Dataset(file_path, tokenizer, max_len)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "def train_model(model, data_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    return total_loss / len(data_loader), accuracy, f1\n",
    "\n",
    "def predict_probabilities(model, data_loader, device):\n",
    "    model.eval()\n",
    "    sentence_probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            sentence_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())  \n",
    "    return np.array(sentence_probs)\n",
    "\n",
    "def calculate_uncertainty_weights(predictions):\n",
    "    mean_prediction = np.mean(predictions, axis=0)\n",
    "    variance = np.var(predictions, axis=0) + 1e-10\n",
    "    uncertainties = []\n",
    "\n",
    "    for prediction in predictions:\n",
    "        diff_square = (prediction - mean_prediction) ** 2\n",
    "        temp_var = 0.5 * np.log(2 * math.pi * variance)\n",
    "        temp_max = np.maximum(0, temp_var)\n",
    "        final_uncertainty = temp_max + (diff_square / (math.sqrt(3) * variance))\n",
    "        uncertainties.append(final_uncertainty)\n",
    "\n",
    "    weights = 1 / (np.array(uncertainties) + 1e-10)\n",
    "    return weights / weights.sum(axis=0)  \n",
    "\n",
    "\n",
    "def get_grouped_probs(data_loader, model,device):\n",
    "    sentence_probs = predict_probabilities(model, data_loader,device)\n",
    "    return [sentence_probs[i:i+3] for i in range(0, len(sentence_probs), 3)]\n",
    "\n",
    "\n",
    "def compute_weighted_predictions(grouped_probs, weight_type=\"average\"):\n",
    "    weighted_probs = []\n",
    "    for group in grouped_probs:\n",
    "        if weight_type == \"average\":\n",
    "            weights = np.array([1/3, 1/3, 1/3])\n",
    "        elif weight_type == \"uncertainty\":\n",
    "            weights = calculate_uncertainty_weights(group)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown weight type: {weight_type}\")\n",
    "        weighted_probs.append(np.average(group, axis=0, weights=weights))\n",
    "    return np.array(weighted_probs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    transformer_model_name = 'bert-base-uncased'\n",
    "    hidden_dim = 256\n",
    "    output_dim = 5\n",
    "    n_layers = 2\n",
    "    dropout = 0.3\n",
    "    max_len = 128\n",
    "    batch_size = 32\n",
    "    learning_rate = 1e-4\n",
    "    n_epochs = 20\n",
    "    early_stopping_patience = 3\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    sentences = train_data['sentence'].values\n",
    "    tokenizer = BertTokenizer.from_pretrained(transformer_model_name)\n",
    "    \n",
    "    train_loader = create_data_loader('train.csv', tokenizer, max_len, batch_size,shuffle = True)\n",
    "    val_loader = create_data_loader('validation.csv', tokenizer, max_len, batch_size,shuffle = False)\n",
    "    test_data_loader = create_data_loader('test.csv', tokenizer, max_len, batch_size,shuffle = False)\n",
    "    T_TTA_test_data_loader = create_data_loader('T_TTA_enhanced_test.csv', tokenizer, max_len, batch_size,shuffle = False)\n",
    "    R_TTA_test_data_loader = create_data_loader('R_TTA_enhanced_test.csv', tokenizer, max_len, batch_size,shuffle = False)\n",
    "    MSTTA_test_data_loader = create_data_loader('MSTTA_enhanced_test.csv', tokenizer, max_len, batch_size,shuffle = False)\n",
    " \n",
    "    model = BiLSTMModel(transformer_model_name, hidden_dim, output_dim, n_layers, dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = train_model(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_accuracy, val_f1 = evaluate_model(model, val_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "              f\"Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'bilstm_Compare_model.pth') \n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    \n",
    "    model.load_state_dict(torch.load('bilstm_Compare_model.pth'))\n",
    "    test_loss, test_accuracy, test_f1 = evaluate_model(model, test_data_loader, criterion, device)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test F1: {test_f1:.4f}\")\n",
    "    \n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    true_labels = test_df['label'].values\n",
    "\n",
    "    test_simple_probs = predict_probabilities(model, test_data_loader,device)\n",
    "    T_TTA_grouped_probs = get_grouped_probs(T_TTA_test_data_loader, model,device)\n",
    "    R_TTA_grouped_probs = get_grouped_probs(R_TTA_test_data_loader, model,device)\n",
    "    MSTTA_grouped_probs = get_grouped_probs(MSTTA_test_data_loader, model,device)\n",
    "\n",
    "    simple_preds = np.argmax(test_simple_probs, axis=1)\n",
    "    simple_accuracy = accuracy_score(true_labels, simple_preds)\n",
    "    simple_precision = precision_score(true_labels, simple_preds, average='weighted')\n",
    "    simple_recall = recall_score(true_labels, simple_preds, average='weighted')\n",
    "    simple_f1 = f1_score(true_labels, simple_preds, average='weighted')\n",
    "    print(f\"Simple Accuracy: {simple_accuracy:.4f}, Precision: {simple_precision:.4f}, Recall: {simple_recall:.4f}, F1: {simple_f1:.4f}\")\n",
    "\n",
    "    weight_types = [\"average\",  \"uncertainty\"]\n",
    "    results = {}\n",
    "\n",
    "    for weight_type in weight_types:\n",
    "        T_TTA_weighted_probs = compute_weighted_predictions(T_TTA_grouped_probs, weight_type=weight_type)\n",
    "        R_TTA_weighted_probs = compute_weighted_predictions(R_TTA_grouped_probs, weight_type=weight_type)\n",
    "        MSTTA_weighted_probs = compute_weighted_predictions(MSTTA_grouped_probs, weight_type=weight_type)\n",
    "\n",
    "        T_TTA_preds = np.argmax(T_TTA_weighted_probs, axis=1)\n",
    "        R_TTA_preds = np.argmax(R_TTA_weighted_probs, axis=1)\n",
    "        MSTTA_preds = np.argmax(MSTTA_weighted_probs, axis=1)\n",
    "     \n",
    "        true_labels = test_df['label'].values\n",
    "        results[f\"T_TTA {weight_type}\"] = {\n",
    "            \"accuracy\": accuracy_score(true_labels, T_TTA_preds),\n",
    "            \"f1\": f1_score(true_labels, T_TTA_preds, average='weighted'),\n",
    "            \"precision\": precision_score(true_labels, T_TTA_preds, average='weighted'),\n",
    "            \"recall\": recall_score(true_labels, T_TTA_preds, average='weighted')\n",
    "        }\n",
    "        results[f\"R_TTA {weight_type}\"] = {\n",
    "            \"accuracy\": accuracy_score(true_labels, R_TTA_preds),\n",
    "            \"f1\": f1_score(true_labels, R_TTA_preds, average='weighted'),\n",
    "            \"precision\": precision_score(true_labels, R_TTA_preds, average='weighted'),\n",
    "            \"recall\": recall_score(true_labels, R_TTA_preds, average='weighted')\n",
    "        }\n",
    "        results[f\"MSTTA {weight_type}\"] = {\n",
    "            \"accuracy\": accuracy_score(true_labels, MSTTA_preds),\n",
    "            \"f1\": f1_score(true_labels, MSTTA_preds, average='weighted'),\n",
    "            \"precision\": precision_score(true_labels, MSTTA_preds, average='weighted'),\n",
    "            \"recall\": recall_score(true_labels, MSTTA_preds, average='weighted')\n",
    "        }\n",
    "\n",
    "    for method, metrics in results.items():\n",
    "        print(f\"{method} - Accuracy: {metrics['accuracy']:.4f}, Precision: {metrics['precision']:.4f}, Recall: {metrics['recall']:.4f}, F1: {metrics['f1']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd903e2-74b2-4da6-aa1b-d2830fbf9923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
